import os
import torch
from tqdm import tqdm
import re
from PIL import Image  # Th√™m th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

# ================= C·∫§U H√åNH =================
INPUT_FOLDER = "raw_data"       
OUTPUT_FOLDER = "train_new_v1"  
TRIGGER_WORD = "vntrafficpolice" 
TARGET_SIZE = (512, 512) # K√≠ch th∆∞·ªõc m·ª•c ti√™u

FOLDER_MAP = {
    # "bat_giu": "vntrafficpolicebatgiu, arresting, handcuffs, confrontation",
    "chan_dung_nam": "vntrafficpolicechandungnam",
    "chan_dung_nu": "vntrafficpolicechandungnu",
    # "dieu_phoi": "vntrafficpolicedieuphoi, directing traffic, street, standing, hand gesture",
    # "doan_xe": "vntrafficpolicedoanxe, motorcade, riding motorcycle, police bike, formation"
}

MODEL_ID = "Qwen/Qwen2-VL-2B-Instruct"
IMAGE_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.webp', '.bmp'}

os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# ================= LOAD MODEL =================
model = Qwen2VLForConditionalGeneration.from_pretrained(
    MODEL_ID, torch_dtype=torch.bfloat16, device_map="auto", trust_remote_code=True
)
processor = AutoProcessor.from_pretrained(MODEL_ID)

def get_qwen_tags(image_path):
    prompt = (
        "List 10-15 descriptive keywords for this image, separated by commas. "
        "Focus on: uniform details, accessories "
        "background, weather, and camera angle. No full sentences."
    )
    
    messages = [{"role": "user", "content": [
        {"type": "image", "image": f"file://{image_path}"},
        {"type": "text", "text": prompt}
    ]}]

    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, _ = process_vision_info(messages)
    inputs = processor(text=[text], images=image_inputs, padding=True, return_tensors="pt").to("cuda")

    with torch.no_grad():
        generated_ids = model.generate(**inputs, max_new_tokens=100)
        generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]
        tags = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True)[0].strip()
        tags = re.sub(r'^(Keywords|Tags|M√¥ t·∫£):', '', tags, flags=re.IGNORECASE).strip()
        return tags

# ================= X·ª¨ L√ù CH√çNH =================
def main():
    cnt = 0
    tasks = []
    for root, dirs, files in os.walk(INPUT_FOLDER):
        folder_name = os.path.basename(root)
        if folder_name in FOLDER_MAP:
            for file in files:
                if os.path.splitext(file)[1].lower() in IMAGE_EXTENSIONS:
                    tasks.append({
                        'full_path': os.path.join(root, file),
                        'folder_tags': FOLDER_MAP[folder_name],
                        'filename': file,
                        'folder': folder_name
                    })

    print(f"üì¶ ƒêang x·ª≠ l√Ω {len(tasks)} ·∫£nh (Resize & Auto-caption)...")

    for task in tqdm(tasks):
        try:
            # 1. L·∫•y tag t·ª´ AI
            # ai_tags = get_qwen_tags(task['full_path'])
            final_caption = f"{task['folder_tags']}"
            final_caption = final_caption.replace(".", "").strip()
            
            # 2. X·ª≠ l√Ω ·∫£nh: M·ªü, Resize v√† L∆∞u
            new_base_name = f"{task['folder']}_{cnt}"
            # L∆∞u ƒë·ªãnh d·∫°ng .jpg ƒë·ªÉ ƒë·ªìng b·ªô v√† nh·∫π (t√πy ch·ªçn)
            output_img_path = os.path.join(OUTPUT_FOLDER, f"{new_base_name}.jpg")
            
            with Image.open(task['full_path']) as img:
                # Chuy·ªÉn sang RGB (ƒë·ªÅ ph√≤ng ·∫£nh PNG c√≥ k√™nh Alpha g√¢y l·ªói khi l∆∞u JPG)
                img = img.convert("RGB")
                
                # Resize (S·ª≠ d·ª•ng Resampling.LANCZOS cho ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t)
                # L∆∞u √Ω: Code n√†y s·∫Ω n√©n ·∫£nh v·ªÅ 512x512 (c√≥ th·ªÉ g√¢y m√©o n·∫øu ·∫£nh g·ªëc kh√¥ng vu√¥ng)
                img_resized = img.resize(TARGET_SIZE, Image.Resampling.LANCZOS)
                
                # L∆∞u ·∫£nh
                img_resized.save(output_img_path, "JPEG", quality=95)

            # 3. L∆∞u file caption
            with open(os.path.join(OUTPUT_FOLDER, f"{new_base_name}.txt"), "w", encoding="utf-8") as f:
                f.write(final_caption)
            
            cnt += 1
                
        except Exception as e:
            print(f"‚ùå L·ªói: {task['filename']} - {e}")

    print(f"‚úÖ Ho√†n t·∫•t! ƒê√£ l∆∞u {cnt} b·ªô d·ªØ li·ªáu v√†o '{OUTPUT_FOLDER}'")

if __name__ == "__main__":
    main()